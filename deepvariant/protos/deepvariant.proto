// Copyright 2017 Google Inc.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions
// are met:
//
// 1. Redistributions of source code must retain the above copyright notice,
//    this list of conditions and the following disclaimer.
//
// 2. Redistributions in binary form must reproduce the above copyright
//    notice, this list of conditions and the following disclaimer in the
//    documentation and/or other materials provided with the distribution.
//
// 3. Neither the name of the copyright holder nor the names of its
//    contributors may be used to endorse or promote products derived from this
//    software without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.

syntax = "proto3";

import "third_party/nucleus/protos/position.proto";
import "third_party/nucleus/protos/reads.proto";
import "third_party/nucleus/protos/variants.proto";
import "deepvariant/protos/realigner.proto";


package learning.genomics.deepvariant;

// The type of an Allele.
//
// An allele type indicates what kind of event would have produced
// this allele.  An allele can be the reference sequence, a substitution
// of bases, insertion of bases, or deletion of bases. Allele types need not be
// real genetic variants: for example, the SOFT_CLIP type indicates that a read
// contained bases SOFT_CLIPPED away (similar to an insertion), which is often
// indicative of some large event near the start or end of the read.
enum AlleleType {
  // Default should be unspecified:
  // https://docs.google.com/document/d/1oavZD9XB_147ti93MCBoR5HrFKoBh1xkZcTxjInYf0M/edit#heading=h.8ylxmf942vui
  UNSPECIFIED = 0;

  // The allele corresponding to that found in the genome sequence.
  REFERENCE = 1;

  // A substitution of bases that are difference from the genome sequence.
  SUBSTITUTION = 2;

  // An insertion of bases w.r.t. the reference genome.
  INSERTION = 3;

  // A deletion of bases w.r.t. the reference genome.
  DELETION = 4;

  // An allele type produced by a SOFT_CLIP operation during alignment.
  // Maybe indicative of a real genetic event occurring at this position,
  // or may be an data quality / alignment artifact.
  SOFT_CLIP = 5;
}


// An Allele observed in some type of NGS read data.
//
// Conceptually, an Allele is a sequence of bases that represent a type
// of change relative to a reference genome sequence, along with a discrete
// count of the number of times that allele was observed in the NGS data.
message Allele {
  // The string of bases that make up this Allele. Should not be empty.
  // A simple reference allele might have a single base "A", while a complex
  // insertion of the bases "CTG" following that base "A" would have a
  // bases sequence of "ACTG".
  string bases = 1;

  // The type of this allele.
  AlleleType type = 2;

  // The number of times this Allele was seen in the NGS data. The count
  // should be >= 0, where 0 indicates that no observations of the allele
  // were observed (which can happen if you want to record that you checked
  // for some allele in the data and never saw any evidence for it).
  int32 count = 3;
}


// An AlleleCount summarizes the NGS data observed at a position in the genome.
//
// An AlleleCount proto is an key intermediate data structure in DeepVariant
// summarizing the NGS read data covering a site in the genome. It is
// intended to be relatively simple but keep track of the key pieces of
// information about the observed reads and their associated alleles at this
// position so that downstream tools can reconstruct the read coverage, do
// variant calling, and compute reference confidence. It is conceptually similar
// to a samtools read pileup (http://samtools.sourceforge.net/pileup.shtml) but
// without detailed information about bases or their qualities.
//
// The AlleleCount at its core tracks the Alleles observed in reads that overlap
// this position in the genome. Consider a read that has a base, X, aligned to
// the position of interest. If X is a non-reference allele, the AlleleCount
// proto adds a new read name ==> Allele key-value entry to the read_alleles
// map field. If X is the reference allele, the AlleleCount proto increments
// either the ref_supporting_read_count or the ref_nonconfident_read_count
// counter field, depending on read alignment confidence as defined by
// pipeline-specific parameters.
//
// The complexity here is introduced by following the VCF convention of
// representing indel and complex substitution alleles as occurring at the
// preceding base in the genome. So if in fact our base X is followed by a 3 bp
// insertion of acg, than we would in fact not have a count for X at all but
// would see an allele Xacg with a count of 1 (or more if other reads have the
// same allele). The primary contract here is that each aligned base at this
// site goes into a +1 for exactly one allele. A concrete example might
// clarify this logic.  Consider the following alignment of two reads to the
// reference genome:
//
// Position: 123   4567
// Ref:      ATT---TGCT
// Read1:    ATT---TGCT
// Read2:    ATTCCCTG-T
//
// The 'T' base in position 3 of Read 1 matches the reference and so the
// AlleleCount's ref_supporting_read_count is incremented. The 'T' base in
// position 3 of Read 2 also matches the reference, but it is the anchor base
// preceding the 'CCC' insertion. The 'TCCC' INSERTION Allele is therefore added
// to the AlleleCount proto for this position. A deletion occurs in read 2 at
// position 6 as well, which produces a DELETION allele 'GT' at position 5.
// Additionally, because only read 1 has a C base at position 6, the AlleleCount
// at 6 would have no entries in its read_alleles and ref_supporting_read_count
// would be 1.
//
// Another design choice is that spanning deletions don't count as coverage
// under bases, so there's an actual drop in coverage under regions of the
// genome with spanning deletions.  This is classically the difference between
// physical coverage and sequence coverage:
//
//      https://en.wikipedia.org/wiki/Shotgun_sequencing#Coverage
//
// so it's safe to think of an AlleleCount as representing the sequence coverage
// of a position, not its physical coverage.
//
// What this means is that its very straightforward to inspect the reference
// counters and read_alleles in an AlleleCount and determine the corresponding
// alleles for a Variant as well as compute the depth of coverage. This enables
// us to write algorithms to call SNPs, indels, CNVs as well as identify regions
// for assembly using a series of AlleleCount objects rather than the underlying
// read data.
//
// An AlleleCount is a lossy transformation of the raw read data. Fundamentally,
// the digestion of a read into its correspond AlleleCount components loses some
// of this contiguity information provided by reads spanning across multiple
// positions on the genome. None of the specifics of base quality, mapping
// quality, read names, etc. are preserved. Furthermore, an AlleleCount can be
// constructed using only a subset of all of the raw reads (e.g., those that
// pass minimum quality criteria) and even only parts of each read (e.g., if
// the read contains Ns or low quality bases). The data used to compute an
// AlleleCount isn't specified as part of the proto, but is left up to the
// implementation details and runtime parameters of the generating program.
//
// For usability and performance reasons we track reference and alternate allele
// supporting reads in slightly different ways. The number of reads that
// confidently carry the reference allele at this position is stored in
// ref_supporting_read_count. Confidence here means that the read's alignment to
// the reference is reliable. See the Base Alignment Quality (BAQ) paper:
//
// http://bioinformatics.oxfordjournals.org/content/early/2011/02/13/bioinformatics.btr076.full.pdf
//
// For background and motivation. For reads that would have been counted as
// reference supporting but don't have a reliable alignment we instead tally
// those in ref_nonconfident_read_count. Finally, reads that don't have the
// reference allele are stored in a map from the string
// "fragment_name/read_number" to the allele it supports, which by construction
// will always have a count of 1. This allows for more detailed downstream
// analyses of the alt allele containing reads.
//
// Consequentially, the total (usable) coverage at this location is:
//
// coverage =
//    // reads supporting an observed alternate allele.
//    sum(read_allele_i.count)      // [also equal to read_alleles_size()]
//    // All of the reads confidently asserting reference.
//    + ref_supporting_read_count
//    // All of the reads supporting ref without a confident alignment.
//    + ref_nonconfident_read_count
//
message AlleleCount {
  // The position on the genome of this AlleleCount.
  nucleus.genomics.v1.Position position = 1;

  // The reference bases of this AlleleCount. Since AlleleCount currently
  // only represents a single location, this field should always be a
  // single base.
  string ref_base = 2;

  // The number of reads that confidently carry the reference allele at this
  // position.
  int32 ref_supporting_read_count = 3;

  // A map from a read's key to an Allele message containing information about
  // the allele supported by that read at this position. There will be one
  // binding for each usable read spanning this position that supports a
  // non-reference allele. The read's key is a unique string that identifies
  // the read, currently "fragment_name/read_number".
  map<string, Allele> read_alleles = 4;

  // A count of the number of reads that supported the reference allele but
  // whose alignment to the reference genome isn't 100% certain.
  int32 ref_nonconfident_read_count = 5;
}

// A lighter-weight version of AlleleCount.
//
// The only material difference with this proto is that we don't store the map
// from read names to Alleles, but instead have the total number of reads we've
// seen at this position.
message AlleleCountSummary {
  // The Position field of AlleleCount with values inlined here.
  string reference_name = 1;
  int64 position = 2;
  // Same as in AlleleCount.
  string ref_base = 3;
  // Same as in AlleleCount.
  int32 ref_supporting_read_count = 4;
  // This is the total number of reads observed at position.
  int32 total_read_count = 5;
  // Same as in AlleleCount.
  int32 ref_nonconfident_read_count = 6;
}

// A message encapsulating all of the information about a Variant call site for
// consumption by further stages of the DeepVariant data processing workflow.
message DeepVariantCall {
  // A Variant call based on the information in allele_count. Will always be a
  // non-reference variant call (no gVCF or reference records).
  nucleus.genomics.v1.Variant variant = 1;

  // A map from an alt allele in Variant to Read key that support that allele.
  // Every alt allele in the variant will have an entry. Reference supporting
  // reads aren't listed. There may be a special key "UNCALLED_ALLELE" for reads
  // that don't support either the reference allele or any alt allele in the
  // variant. This can happen when the read supports an allele that didn't pass
  // our calling thresholds. The read's key is a unique string that identifies
  // the read constructed as "fragment_read/read_number".
  message SupportingReads {
    repeated string read_names = 1;
  }
  map<string, SupportingReads> allele_support = 2;
}

// Options to control how our AlleleCounter code works.
message AlleleCounterOptions {
  // The number of basepairs to include in each partition of the reference
  // genome. This determines how many map/reduce jobs are used to compute the
  // AlleleCounts. Using a too small value (below 10000 for example) results
  // in having many many intervals to process which may be a performance problem
  // for the tool. Using too large of a value will result in difficulty
  // parallelizing the computation as there will be too few work units to
  // parallelize and each unit will use a lot of memory.
  int32 partition_size = 1;

  // The requirements for reads to be used when counting alleles.
  nucleus.genomics.v1.ReadRequirements read_requirements = 2;
}

// Variant call for a single site, in a pseudo-biallelic manner. This is an
// intermediate format for call_variants.py that needs to be merged if there
// are multiallelics.
// The `variant` here likely doesn't have fully filled information for output to
// a VCF file yet.
message CallVariantsOutput {
  nucleus.genomics.v1.Variant variant = 1;

  // The alt allele indices is represented as a sub-message so that it's easier
  // to re-use as a standalone proto for encoding+decoding.
  message AltAlleleIndices {
    repeated int32 indices = 1;
  }
  AltAlleleIndices alt_allele_indices = 2;

  repeated double genotype_probabilities = 3;

  message DebugInfo {
    int32 predicted_label = 1;
    bool has_insertion = 2;
    bool has_deletion = 3;
    bool is_snp = 4;
  }
  DebugInfo debug_info = 4;
}

// Options to control how our candidate VariantCaller works.
message VariantCallerOptions {
  // Alleles occurring at least this many times in our AlleleCount are
  // considered candidate variants.
  int32 min_count_snps = 1;
  int32 min_count_indels = 2;

  // Alleles that have counts at least this fraction of the all counts in an
  // AlleleCount are considered candidate variants.
  float min_fraction_snps = 3;
  float min_fraction_indels = 4;

  // If provided, we will emit "candidate" variant records at a random fraction
  // of otherwise non-candidate sites. Useful for training.
  float fraction_reference_sites_to_emit = 5;

  // The random seed to use in our variant caller. If not provided, a truly
  // random seed will be used.
  uint32 random_seed = 6;

  // The name of the sample we will put in our VariantCall field of constructed
  // variants.
  string sample_name = 7;

  // The probability that a non-reference allele is actually an error.
  float p_error = 8;

  // The maximum genotype quality we'll emit for a reference site.
  int32 max_gq = 9;

  // The width of a GQ bin used to quantize the raw double GQ
  // values into coarser-grained bins than just 1 integer unit. See QuantizeGQ
  // for more information about the quantization process.
  int32 gq_resolution = 10;

  // The ploidy of this sample. For humans, this is 2 (diploid). Currently the
  // code makes implicit assumptions that the ploidy is 2, but this value is
  // used in calculations directly involving ploidy so when we generalize the
  // caller to handle other ploidy values we don't have to update all of those
  // constants.
  int32 ploidy = 11;
}

// Options to control how our we label variant calls.
message VariantLabelerOptions {
  // Currently there are no options for VariantLabeler.
}

// Options to control how our we construct pileup images.
// Next ID: 22.
message PileupImageOptions {
  // The height, in pixels, of the pileup image we'll construct.
  int32 height = 1;
  // The width, in pixels, of the pileup image we'll construct.
  int32 width = 2;

  // We include at the top of the each image a band of reference pixels with
  // this specified height.
  int32 reference_band_height = 3;

  // Controls how bases are encoded as red pixel values.
  //
  // A is base_color_offset_a_and_g + base_color_stride * 3
  // G is base_color_offset_a_and_g + base_color_stride * 2
  // T is base_color_offset_t_and_c + base_color_stride * 1
  // C is base_color_offset_t_and_c + base_color_stride * 0
  //
  // The offset in red color space for A and G bases.
  int32 base_color_offset_a_and_g = 4;
  // The offset in red color space for T and C bases.
  int32 base_color_offset_t_and_c = 5;
  // Each base color is offset from each other by this stride.
  int32 base_color_stride = 6;

  // The alpha value applied to pixels in the reference genome band.
  float reference_alpha = 7;
  // The base quality we assume for the reference genome bases.
  int32 reference_base_quality = 8;

  // The alpha to apply to reads that support our alt alleles.
  float allele_supporting_read_alpha = 9;
  // The alpha to apply to reads that do not support our alt alleles.
  float allele_unsupporting_read_alpha = 10;
  // The alpha to apply to a base that matches the reference sequence.
  float reference_matching_read_alpha = 11;
  // The alpha to apply to a base that doesn't matches the reference sequence.
  float reference_mismatching_read_alpha = 12;

  // The character we'll use when encoding insertion/deletion anchor bases.
  string indel_anchoring_base_char = 13;

  // The color value to use for reads on the positive strand.
  int32 positive_strand_color = 14;
  // The color value to use for reads on the negative strand.
  int32 negative_strand_color = 15;

  // The maximum base quality we'll allow in PIC. Base qualities above this
  // value are treated as being base_quality_cap.
  int32 base_quality_cap = 16;

  // Extend read windows by a small amount when calculating overlap with calls.
  // This is important to include all the reads involved in deletions in a
  // pileup image.
  int32 read_overlap_buffer_bp = 17;

  // The requirements for reads to be used when creating pileup images.
  nucleus.genomics.v1.ReadRequirements read_requirements = 18;

  enum MultiAllelicMode {
    UNSPECIFIED = 0;
    ADD_HET_ALT_IMAGES = 1;
    NO_HET_ALT_IMAGES = 2;
  }
  MultiAllelicMode multi_allelic_mode  = 19;

  // The maximum mapping quality we'll allow in PIC. Mapping qualities above
  // this value are treated as being mapping_quality_cap.
  int32 mapping_quality_cap = 20;

  // The random seed to use in our Pileup Image Creation.
  uint32 random_seed = 21;
}


// High-level options that encapsulates all of the parameters needed to run
// DeepVariant end-to-end.
// Next ID: 28.
message DeepVariantOptions {
  // A list of contig names we never want to call variants on. For example,
  // chrM in humans is the mitocondrial genome and the caller isn't trained to
  // call variants on that genome.
  repeated string exclude_contigs = 1;

  // List of regions where we want to call variants. If missing, we will call
  // variants throughout the entire genome.
  repeated string calling_regions = 2;

  // Fixed random seed to use for DeepVariant itself.
  uint32 random_seed = 3;

  // The number of cores to use when running DeepVariant. Must be >= 1.
  int32 n_cores = 4;

  // Options to control how we run the AlleleCounter.
  AlleleCounterOptions allele_counter_options = 5;

  // Options to control how we call candidate variants.
  VariantCallerOptions variant_caller_options = 6;

  // Options to control how we generate pileup images.
  PileupImageOptions pic_options = 7;

  // Options to control how we label our examples.
  VariantLabelerOptions labeler_options = 8;

  // Only reads satisfying these requirements will be used in DeepVariant.
  // This parameters are propagated as appropriate to read_requirement fields
  // in our tool-specific options.
  nucleus.genomics.v1.ReadRequirements read_requirements = 9;

  // Options to control out input data sources and output data sinks.
  // Path to our genome reference.
  string reference_filename = 10;
  // Path to our source of NGS reads.
  string reads_filename = 11;
  // Path where we'll write out our candidate variants.
  string candidates_filename = 12;
  // Path to examples.
  string examples_filename = 13;
  // Path to a list of regions we are confident in, for determining which
  // candidate variants get labels.
  string confident_regions_filename = 14;
  // Path to the truth variants, for use in labeling our examples.
  string truth_variants_filename = 15;
  // Path where we should put our gVCF records.
  string gvcf_filename = 16;

  // The name of the deep learning model to use with DeepVariant.
  string model_name = 17;

  enum Mode {
    UNSPECIFIED = 0;
    CALLING = 1;
    TRAINING = 2;
  }
  Mode mode = 18;

  // The minimum fraction of basepairs that must be shared by all contigs common
  // to DeepVariant inputs and the reference contigs alone. If the common
  // contigs cover less than min_shared_contig_basepairs of the reference genome
  // contigs DeepVariant will signal an error that the input datasets aren't
  // from compatible genomes.
  float min_shared_contigs_basepairs = 19;

  // The task identifier, as an integer, of this task. If we are running with
  // multiple tasks processing the same inputs into sharded outputs, this id
  // should be set to a number from 0 (master) to N - 1 to indicate which of the
  // tasks we are currently processing.
  int32 task_id = 20;

  // When running in sharded output mode (i.e., writing outputs to foo@N), this
  // field captures the number of sharded outputs (i.e., N). When not running in
  // sharded output mode, this field should be 0.
  int32 num_shards = 21;

  // Options to control realigner module.

  // Whether the realigner should be enabled.
  bool realigner_enabled = 22;
  // Settings for the realigner module.
  learning.genomics.deepvariant.RealignerOptions realigner_options = 23;

  // The maximum number of reads per partition that we consider before following
  // processing such as sampling and realigner.
  int32 max_reads_per_partition = 24;

  // Should we downsample our reads and if so, by how much? If == 0.0 (default),
  // no downsampling occurs. But if set, must be between 0.0 and 1.0 and
  // indicates the probability that a read will be kept (randomly) when read
  // from the input. This option makes it easy to simulate lower coverage data.
  float downsample_fraction = 25;

  // List of regions where we DON'T want to call variants. If missing, no
  // regions will be excluded from calling.
  repeated string exclude_calling_regions = 26;

  // An enumeration of all of the labeler algorithms we support in DeepVariant.
  enum LabelerAlgorithm {
    UNSPECIFIED_LABELER_ALGORITHM = 0;
    // The labeling algorithm used with DeepVariant 0.4-0.5, which does position
    // matching to find truth variant to label our candidates.
    POSITIONAL_LABELER = 1;
    // A haplotype-aware labeling algorithm, similar to hap.py xcmp, that looks
    // for genotypes for candidate variants that produce haplotypes that match
    // those implied by the genotypes of our truth variants. Produces more
    // accurate labels than the POSITIONAL_LABELER labeling algorithm.
    HAPLOTYPE_LABELER = 2;
  }
  // The labeling algorithm we are using in this DeepVariant run. Only needed
  // when in CALLING mode.
  LabelerAlgorithm labeler_algorithm = 27;
}

// Config describe information needed for a dataset that can be used for
// training, validation, or testing.
message DeepVariantDatasetConfig {
  // A human-readable name of the dataset.
  string name = 1;

  // Full path of the tensorflow.Example TFRecord file.
  string tfrecord_path = 2;

  // Number of examples for this dataset. Right now this needs to be manually
  // filled in order to compute how the learning rate decays, and also used
  // in make_training_batches.
  int32 num_examples = 3;
}

// Next ID: 3.
message DeepVariantInputDatasets {
  // Fields in Dataset are provided to make_examples.py as arguments.
  // Next ID: 9.
  message Dataset {
    // Path to a BED file that contains the confident regions for creating TF
    // examples.
    string confident_regions = 1;
    // Path to a BAM file that contains the DNA reads for creating TF examples.
    string reads = 2;
    // Path to a FASTA file that contains the reference genome.
    string ref = 3;
    // Path to a VCF file that contains the truth variants information.
    string truth_variants = 4;
    // Space-separated list of regions we want to process.
    string regions = 5;
    // A float number (< 1.0) that allows make_examples to sample more HOMREF
    // examples. The value can also be "null" which means using the default.
    string training_random_emit_ref_sites = 6;
    // List of downsample_fractions. Accepted values are strings that can be
    // parsed into a value between (0, 1), or the string "null" which means
    // no downsampling.
    repeated string downsample_fractions = 7;

    // Space-separated list of regions we want to exclude.
    string exclude_regions = 8;
  }
  repeated Dataset datasets = 1;
  string group_name = 2;
}

message DeepVariantInputDatasetsGroup {
  repeated DeepVariantInputDatasets groups = 1;
}
